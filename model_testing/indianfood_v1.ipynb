{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aryan401/indianfoodcnn?scriptVersionId=142203477\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch import nn\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.utils.data.dataloader import DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom time import time\nfrom statistics import mean","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-07T06:23:34.434902Z","iopub.execute_input":"2023-09-07T06:23:34.435179Z","iopub.status.idle":"2023-09-07T06:23:39.40951Z","shell.execute_reply.started":"2023-09-07T06:23:34.435154Z","shell.execute_reply":"2023-09-07T06:23:39.408379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tranform = transforms.Compose([\n    transforms.Resize((224,224)), \n    transforms.ToTensor(), \n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\ntrain_dataset = torchvision.datasets.ImageFolder(root='/kaggle/input/indian-food-16/Train', transform=tranform)\ntest_dataset = torchvision.datasets.ImageFolder(root='/kaggle/input/indian-food-16/Test', transform=tranform)\nvalid_dataset = torchvision.datasets.ImageFolder(root='/kaggle/input/indian-food-16/Validate', transform=tranform)\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nprint('Train DataSet len:',len(train_dataset))\nprint('Valid DataSet len:',len(valid_dataset))\nprint('Test DataSet len:',len(test_dataset))\nprint('Total DataSet Classes:',len(test_dataset.classes))","metadata":{"execution":{"iopub.status.busy":"2023-09-07T06:23:39.415346Z","iopub.execute_input":"2023-09-07T06:23:39.417967Z","iopub.status.idle":"2023-09-07T06:23:40.016059Z","shell.execute_reply.started":"2023-09-07T06:23:39.417926Z","shell.execute_reply":"2023-09-07T06:23:40.014839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.ConvSet_1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.ConvSet_2 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.FC_Layers = nn.Sequential(\n            nn.Linear(401408, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(1024, 64),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(64, 16),\n        )\n    def forward(self, x):\n        out = self.ConvSet_1(x)\n        out = self.ConvSet_2(out)\n        out = out.reshape(out.shape[0], -1)\n        out = self.FC_Layers(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-09-07T06:23:40.017515Z","iopub.execute_input":"2023-09-07T06:23:40.018059Z","iopub.status.idle":"2023-09-07T06:23:40.028485Z","shell.execute_reply.started":"2023-09-07T06:23:40.018023Z","shell.execute_reply":"2023-09-07T06:23:40.027404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CNN()\nmodel = model.to(device=device)\nprint(model)\nprint('Device: ',device)","metadata":{"execution":{"iopub.status.busy":"2023-09-07T06:23:40.030737Z","iopub.execute_input":"2023-09-07T06:23:40.031159Z","iopub.status.idle":"2023-09-07T06:23:46.975182Z","shell.execute_reply.started":"2023-09-07T06:23:40.031126Z","shell.execute_reply":"2023-09-07T06:23:46.974093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 1e-4\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr= learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-09-07T06:24:06.022243Z","iopub.execute_input":"2023-09-07T06:24:06.022694Z","iopub.status.idle":"2023-09-07T06:24:06.033274Z","shell.execute_reply.started":"2023-09-07T06:24:06.022656Z","shell.execute_reply":"2023-09-07T06:24:06.032389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 50 # 1+ 5 + 20 + 20\nprint(f\"Train DataLoader Size: {len(train_dataloader)}\")\nprint(f\"Valid DataLoader Size: {len(valid_dataloader)}\")\nfor epoch in range(num_epochs):\n    global_time = time()\n    local_time_chg = []\n    loss_ep = 0\n    for images, labels in train_dataloader:\n        local_time = time()\n        images = images.to(device=device)\n        labels = labels.to(device=device) \n        optimizer.zero_grad()\n        scores = model(images)\n        loss = criterion(scores,labels)\n        loss.backward()\n        optimizer.step()\n        loss_ep += loss.item()\n        local_time_chg.append(time()-local_time)\n        if len(local_time_chg) % 10 == 0:\n            print(f\"Step Verified: {len(local_time_chg)}\")\n        \n    with torch.no_grad():\n        correct = 0\n        total = 0\n        print(\"Starting Validation Test...\")\n        for images, labels in valid_dataloader:\n            images = images.to(device=device)\n            labels = labels.to(device=device) \n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        print(f'Accuracy of the Model on the {len(valid_dataset)} Valid Images: {100*(correct /total)} %')\n\n    print (f'Epoch [{epoch+1}/{num_epochs}] | Loss: {round(loss_ep/len(train_dataloader), 5)} | Step Time: {mean(local_time_chg)} | Epoch Time: {time() - global_time}')","metadata":{"execution":{"iopub.status.busy":"2023-09-07T06:49:31.332815Z","iopub.execute_input":"2023-09-07T06:49:31.333168Z","iopub.status.idle":"2023-09-07T06:49:37.531045Z","shell.execute_reply.started":"2023-09-07T06:49:31.333139Z","shell.execute_reply":"2023-09-07T06:49:37.529376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/IndianFoodCNN.pt\")\nmodel = CNN()","metadata":{"execution":{"iopub.status.busy":"2023-09-07T06:48:24.034791Z","iopub.execute_input":"2023-09-07T06:48:24.035151Z","iopub.status.idle":"2023-09-07T06:48:31.581218Z","shell.execute_reply.started":"2023-09-07T06:48:24.03512Z","shell.execute_reply":"2023-09-07T06:48:31.580243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/working/IndianFoodCNN.pt\"))\nmodel = model.to(device=device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-09-07T06:49:25.889178Z","iopub.execute_input":"2023-09-07T06:49:25.889565Z","iopub.status.idle":"2023-09-07T06:49:27.902054Z","shell.execute_reply.started":"2023-09-07T06:49:25.889532Z","shell.execute_reply":"2023-09-07T06:49:27.900972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_dataloader:\n        images = images.to(device=device)\n        labels = labels.to(device=device) \n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    print('Accuracy of the Model on the {} Test Images: {}%'.format(len(test_dataset), 100*correct /total))","metadata":{"execution":{"iopub.status.busy":"2023-09-07T06:49:42.373184Z","iopub.execute_input":"2023-09-07T06:49:42.373574Z","iopub.status.idle":"2023-09-07T06:49:46.085275Z","shell.execute_reply.started":"2023-09-07T06:49:42.373541Z","shell.execute_reply":"2023-09-07T06:49:46.084447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}